<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[logistic regression]]></title>
    <url>%2F2018%2F04%2F23%2Flogistic-regression%2F</url>
    <content type="text"><![CDATA[1 逻辑斯蒂分布(logistic distribution)定义：设X是连续随机变量，X服从logistic分布是指X具有下列分布函数和密度函数： $$ F = P(X \leq x)=\frac{1}{1+exp(-\frac{(x-\mu)}{\gamma})} $$$$ f= F’(x) = \frac{exp(-\frac{(x-\mu)}{\gamma})}{\gamma[1+exp(-\frac{(x-\mu)}{\gamma})]^2} $$式中，$\mu$为位置参数，$\gamma &gt; 0$为形状参数。 其分布图形如下： F曲线在中心附近增长速度较快，在两端增长速度较慢。形状参数$\gamma$值越小，曲线在中心附近增长得越快。 2 二项逻辑斯蒂回归模型定义：二项逻辑斯蒂回归模型是如下的条件概率分布$$P(y=1\mid x) = \frac{\exp(\omega^\top x+b)}{1 + \exp(\omega^\top x+b)} \tag{1}$$$$P(y=0\mid x) = \frac{1}{1 + \exp(\omega^\top x+b)} \tag{2}$$这里，$x\in R^n$是输入，$y\in {0,1 }$是输出，$\omega \in R^n$和$b\in R$是参数，$\omega$称为权值向量，$b$称为偏置，$\omega^\top x$为$w$和$x$的内积。 对于给定的输入实例$x$，按照(1)式和(2)式可以分别求得$P(y=1\mid x)$和$P(y=0\mid x)$。逻辑斯蒂回归比较这两个条件概率值的大小，将实例$x$分到概率值较大的那一类。 定义：一个事件的几率(odds)是指该事件发生的概率与该事件不发生的概率的比值。如果事件发生的概率为$p$，那么该事件的几率是$\frac{p}{1-p}$，该事件的对数几率(log odds)或者logit函数是$$logit(p)=log\frac{p}{1-p}$$对于逻辑斯蒂回归而言，由(1),(2)式得$$log\frac{P(y=1\mid x)}{1-P(y=1\mid x)}=\omega^\top x+b$$也就是说，在逻辑斯蒂回归模型中，输出$y=1$的对数几率是由输入$x$的线性函数表示的模型。 3 模型参数估计对于给定的训练数据集$T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中$x_i\in R^n$，$y_i\in {0,1 }$，可以应用极大似然估计法估计模型参数，从而得到逻辑斯蒂回归模型。 设：$P(y=1\mid x)=\pi(x)$，$P(y=0\mid x)=1-\pi(x)$则似然函数为：$$\prod_{i=1}^N [\pi(x_i)]^{y_i}[1-\pi(x_i)]^{1-y_i}$$对数似然函数为：$$\begin{aligned}L(\omega,b)&amp;=\sum_{i=1}^N [y_i\ln(\pi(x_i))+(1-y_i)\ln(1-\pi(x_i))] \&amp;= \sum_{i=1}^N [y_i\ln\frac{\pi(x_i)}{1-\pi(x_i)}+\ln(1-\pi(x_i))] \&amp;=\sum_{i=1}^N \left [ y_i(\omega^\top x+b) -\ln \left ( 1+ exp(\omega^\top x+b) \right )\right ]\end{aligned}$$这样，问题就变成了以对数似然函数为目标函数的最优化问题，逻辑斯蒂回归学习中通常采用的方法是梯度下降法及牛顿法。 4 梯度下降(上升)法求解利用梯度下降(上升)求解对数似然函数：$L(\omega,b)$因为要使得似然函数最大，我们使用梯度上升法。为了计算方便，我们将权值向量和输入向量加以扩充，仍记作$\omega,x$，即$$\omega=(\omega^{(1)},\omega^{(2)},…,\omega^{(n)},b),\;x=(x^{(1)},x^{(2)},…,x^{(n)},1)$$ 梯度上升求解:这时$$\omega_{new}^\top x_{new}=\omega_{old}^\top x_{old}+b_{old}$$我们令：$$z=\omega^\top x; z_i=\omega^\top x_i;z_i^{(k)}=\omega_k^\top x_i$$$$\pi(z) = \frac{exp(z)}{1+exp(z)}= \frac{1}{1+exp(-z)} $$ 于是有$$l(\omega)=\sum_{i=1}^N \left [ y_i(\omega^\top x) -\ln \left ( 1+ exp(\omega^\top x) \right )\right ]$$先求各个偏导数：$$\begin{aligned}\frac{\partial l(\omega)}{\partial \omega^{(j)}}&amp;=\frac{\partial }{\partial \omega^{(j)}}\left ( \sum_{i=1}^N \left [ y_i(\omega^\top x) -\ln \left ( 1+ exp(\omega^\top x) \right )\right ]\right ) \ &amp;= \sum_{i=1}^N \left [ y_i x_i^{(j)} - \frac{exp(w^\top x_i)}{1+exp(w^\top x_i)} x_i^{(j)}\right ] \ &amp;= \sum_{i=1}^N \left ( y_i - \frac{exp(w^\top x_i)}{1+exp(w^\top x_i)} \right ) x_i^{(j)} \ &amp;= \sum_{i=1}^N ( y_i - \pi(z_i) ) x_i^{(j)}\end{aligned}$$ 得到参数的迭代公式：$$\omega_{k+1}^{(j)} = \omega_{k}^{(j)} +\lambda_k \cdot (-\sum_{i=1}^N ( y_i - \pi(z_i^{(k)}) ) ) x_i^{(j)} $$令$$s^{(k)}=(s_1^{(k)},s_2^{(k)},…,s_N^{(k)}),s_i^{(k)}= y_i - \pi_k(z_i^{(k)}) $$则$$\begin{aligned}\triangledown l(\omega_{k}) &amp;= ( \frac{\partial l(\omega_{k})}{\partial \omega_{k}^{(0)}}, \frac{\partial l(\omega_{k})}{\partial \omega_{k}^{(1)}},…, \frac{\partial l(\omega_{k})}{\partial \omega_{k}^{(n)}} ) \ &amp;= [\sum_{i=1}^N ( y_i - \pi(z_i^{(k)}) ) x_i^{(j)}],j=0,1,…,n \&amp;=[\sum_{i=1}^N s_i^{(k)} x_i^{(j)}] \&amp;=s^{(k)}\cdot x\\end{aligned}$$ 注意梯度上升为正梯度方向,即 $ P^{(k)} = \triangledown l(\omega_{k})$即有： $$\omega_{k+1} = \omega_{k} +\lambda_k P^{(k)} = \omega_{k} +\lambda_k \cdot (s^{(k)}\cdot x) $$ 求解一维搜索$$l(\omega_{k}+\lambda_k P^{(k)})=\max_{\lambda \geqslant 0}l(\omega_{k}+\lambda \cdot P^{(k)})$$ 得 $$\lambda_k=\frac{ - \triangledown l(\omega_{k})^\top \triangledown l(\omega_{k}) }{\triangledown l(\omega_{k})^\top H(\omega_{k}) \triangledown l(\omega_{k})} $$ 其中 $$H(\omega_{k})=\begin{bmatrix}\frac{\partial^2 l(\omega_{k})}{\partial \omega_{k}^{(p)}\partial \omega_{k}^{(q)}}\end{bmatrix} ;p,q \in {0,1,2,..,n}$$ $$\frac{\partial^2 l(\omega_{k})}{\partial \omega_{k}^{(p)}\partial \omega_{k}^{(q)}} = \sum_{i=1}^N \pi’(\omega_k x_i) ( x_i^{(p)} x_i^{(q)}) $$ $$\pi’(z) = \frac{exp(-z)}{(1+exp(-z))^2}=\pi(z)(1-\pi(z))$$ 5 模型的优缺点缺点： 逻辑回归需要大样本量，因为最大似然估计在低样本量的情况下不如最小二乘法有效。 为防止过拟合和欠拟合，应该让模型构建的变量是显著的。 对模型中自变量多重共线性较为敏感，需要对自变量进行相关性分析，剔除线性相关的变量。 优点：模型更简单，好理解，实现起来，特别是大规模线性分类时比较方便 6 模型实现见我GitHub。 7 最后在写的过程中才发现，没写一次都要花挺长的时间去理解以及使用markdown码上数学公式，但是这都很大的促进了我对原理的理解！ 参考资料 《统计学习方法》李航 著 清华大学出版社《机器学习实战》Peter Harrington 著 人民邮电出版社《运筹学》第四版 清华大学出版社]]></content>
      <categories>
        <category>machine_leanring</category>
        <category>code</category>
      </categories>
      <tags>
        <tag>machine_leanring</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[my kmeans]]></title>
    <url>%2F2018%2F04%2F15%2Fmy-kmeans%2F</url>
    <content type="text"></content>
      <categories>
        <category>machine_leanring</category>
        <category>code</category>
      </categories>
      <tags>
        <tag>machine_leanring</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度下降法]]></title>
    <url>%2F2018%2F04%2F02%2F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%2F</url>
    <content type="text"><![CDATA[梯度下降法原理&amp;#8195&amp;#8195梯度下降法是求解无约束最优化问题的一种最常用的迭代法。顾名思义，梯度下降法的计算过程就是沿梯度下降的方向求解极小值（也可以沿梯度上升方向求解极大值）。 &amp;#8195&amp;#8195假设$f(x)$是$R^n$上具有一阶连续偏导数的函数，要求解的无约束最优化问题是$$\min_{x\in R^n} f(x)$$$x^*$表示目标函数的极小值点。 选取适当的初值$x^{(0)}$，不断迭代，更新$x$的值，进行目标函数的极小化，直到收敛。由于负梯度方向是使函数值下降最快的方向，在迭代的每一步，以负梯度方向更新$x$的值，从而达到减少函数值的目的。 &amp;#8195&amp;#8195由于$f(x)$具有一阶连续偏导数，若第k次迭代值为$x^{(k)}$，则可将$f(x)$在$x^{(k)}$附近进行一阶泰勒展开：$$f(x)=f(x^{(k)})+g_k^ \top \cdot(x-x^{(k)})$$其中$g_k =g(x^{(k)})= -\triangledown f(x^{(k)}) $为$f(x)$在$x^{(k)}$的梯度(梯度上升为正号)。&amp;#8195&amp;#8195求出第k+1次迭代值$x^{(k+1)}$:$$x^{(k+1)}\leftarrow x^{(k)}+\lambda_k P^{(k)} $$ 其中，$p^{(k)}$是搜索方向，取负梯度方向$P^{(k)}=-\triangledown f(x^{(k)}) $，$\lambda_k$是步长，由一维搜索确定，即$\lambda_k$使得$$f(x^{(k)}+\lambda_k P^{(k)})=\min_{\lambda \geqslant 0}f(x^{(k)}+\lambda \cdot p^{(k)})$$ 一维搜索有个十分重要的性质：在搜索方向上所得最优点处目标函数的梯度和该搜索方向正交。定理: 设目标函数$f(x)$具有一阶连续偏导数，$x^{(k+1)}$由如下规则产生$$ \left{ \begin{array}{c} \lambda_k: \min_\lambda f(x^{(k)}+\lambda P^{(k)}) \ x^{(k+1)} = x^{(k)}+\lambda_k P^{(k)} \end{array} \right.$$&#160;则有$$-\triangledown f(x^{(k+1)}) P^{(k)}=0 \tag{1}$$证明: 构造函数$\varphi(\lambda)=f(x^{(k)}+\lambda P^{(k)})$，则得$$ \left{ \begin{array}{c} \varphi(\lambda_k)= \min_\lambda \varphi(\lambda) \ x^{(k+1)} = x^{(k)}+\lambda_k P^{(k)} \end{array} \right.$$即$\lambda_k$为$\varphi(\lambda)$的极小值点。此外$\varphi’(\lambda)=\triangledown f(x^{(k)}+\lambda P^{(k)})^\top P^{(k)}$。由$\varphi’(\lambda)|_{\lambda=\lambda_k}=0$可得$$\triangledown f(x^{(k)}+\lambda_k P^{(k)})^\top P^{(k)}=\triangledown f(x^{(k+1)})^\top P^{(k)}=0$$定理得证。 为什么$P^{(k)}=-\triangledown f(x^{(k)})$?&amp;#8195&amp;#8195因为对于充分小的$\lambda$，只要$$f(x^{(k)})^\top P^{(k)}&lt;0 \tag{2}$$就可以保证$$f(x^{(k)}+\lambda_k P^{(k)})&lt;f(x^{(k)}) \tag{3}$$&amp;#8195&amp;#8195现在考察不同的$P^{(k)}$。假定$P^{(k)}$的模一定(且不为零)，并设$\triangledown f(x^{(k)})$(否则，$x^{(k)}$是平稳点)，使得(2)式成立的$P^{(k)}$有无限多个，为了使目标函数数值能得到尽量大的改善，必须寻求使$f(x^{(k)})^\top P^{(k)} $取最小值的$P^{(k)}$，因为有$$f(x^{(k)})^\top P^{(k)}=|f(x^{(k)})| \cdot |P^{(k)}| \cdot \cos\theta$$式中$\theta$为$f(x^{(k)})$和$P^{(k)}$的夹角。当$P^{(k)}$与$f(x^{(k)})$反向时，$\theta=180°,\cos\theta=-1$。这时式(2)成立，且其左端取得最小值。 一维搜索&amp;#8195&amp;#8195为了得到下一个近似极小值点，在选定了搜索方向之后，还要确定步长$\lambda$。当采用可接受点算法时，就是取某一$\lambda$进行试算，看是否满足不等式(3)，若上述不等式成立，就可以迭代下去。否则缩小$\lambda$使得其满足不等式(3)。&amp;#8195&amp;#8195另一种方法就是在负梯度方向的一维搜索，来确定使$f(x^{(k)})$最小的$\lambda_k$。最常用的有试探法(斐波拉契，0.618法)，插值法(抛物线插值，三次插值)，微积分中的求根法(切线法、二分法等)等。 &amp;#8195&amp;#8195若$f(x)$具有二阶连续偏导数，在$x^{(k)}$作$f(x^{(k)}-\lambda \triangledown f(x^{(k)}) )$的泰勒展开：$$f(x^{(k)}-\lambda \triangledown f(x^{(k)})) \approx f(x^{(k)}) -\triangledown f(x^{(k)})^\top \lambda \triangledown f(x^{(k)}) + \frac{1}{2}\lambda \triangledown f(x^{(k)})^\top H(x^{(k)}) \lambda \triangledown f(x^{(k)})$$对$\lambda$求导并且令其等于零，则得近似最佳步长$$\lambda_k=\frac{ \triangledown f(x^{(k)})^\top \triangledown f(x^{(k)}) }{\triangledown f(x^{(k)})^\top H(x^{(k)}) \triangledown f(x^{(k)})} \tag{4}$$其中$$H(x^{(k)})=\begin{bmatrix}\frac{\partial^2 f(x^{(k)}))}{\partial x_1^2} &amp; \frac{\partial^2 f(x^{(k)}))}{\partial x_1 \partial x_2} &amp; … &amp;\frac{\partial^2 f(x^{(k)}))}{\partial x_1 \partial x_n} \\frac{\partial^2 f(x^{(k)}))}{\partial x_2 \partial x_1} &amp; \frac{\partial^2 f(x^{(k)}))}{\partial x_2^2} &amp; …&amp;\frac{\partial^2 f(x^{(k)}))}{\partial x_2 \partial x_n} \…&amp;&amp;&amp; \\frac{\partial^2 f(x^{(k)}))}{\partial x_n \partial x_1} &amp; \frac{\partial^2 f(x^{(k)}))}{\partial x_n \partial x_2} &amp; …&amp;\frac{\partial^2 f(x^{(k)}))}{\partial x_n^2} \\end{bmatrix}$$为$f(x)$在点$x^{(k)}$处的海赛(Hesse)矩阵。可见近似最佳步长不只与梯度有关，还与海赛矩阵H也有关系，计算起来比较麻烦。&amp;#8195&amp;#8195有时，将搜索方向$P^{(k)}$的模长规格化为1，在这种情况下$$P^{(k)}=\frac{-\triangledown f(x^{(k)})}{ |\triangledown f(x^{(k)})|}$$同时，式(4)变为$$\lambda_k=\frac{ \triangledown f(x^{(k)})^\top \triangledown f(x^{(k)}) |\triangledown f(x^{(k)})| }{\triangledown f(x^{(k)})^\top H(x^{(k)}) \triangledown f(x^{(k)})} $$ 固定步长有一点需要注意的是步长a固定时的大小，如果a太小，则会迭代很多次才找到最优解，若a太大，可能跳过最优，从而找不到最优解。 算法梯度下降法算法如下： 输入：目标函数$f(x)$，梯度函数$g(x)=-\triangledown f(x)$，计算精度$\varepsilon $; 输出：$f(x)$的极小值点$x^$。(1). 取初始值$x^{(0)}\in R^n$，置k=0;(2). 计算$f(x^{(k)})$;(3). 计算梯度$g_k =g(x^{(k)})$，当$\left | g_k\right | &lt; \varepsilon$时，停止迭代，令$x^=x^{(k)}$；否则令$P^{(k)}=-g(x^{(k)})$，求$\lambda_k$，使得$$f(x^{(k)}+\lambda_k p_k)=\min_{\lambda \geqslant 0}f(x^{(k)}+\lambda \cdot P^{(k)})$$(4). 置$x^{(k+1)}=x^{(k)}+\lambda_k P^{(k)} $，计算$f(x^{(k+1)})$，当$\left | f(x^{(k+1)})-f(x^{(k)}) \right | &lt; \varepsilon$或$\left | x^{(k+1)} - x^{(k)}\right | &lt; \varepsilon$时，停止迭代，令$x^*=x^{(k)}$；否则置$k=k+1$，转(3)。 随机梯度下降名字中已经体现了核心思想，即随机选取一个点做梯度下降，而不是遍历所有样本后进行参数迭代。 因为梯度下降法的代价函数计算需要遍历所有样本，而且是每次迭代都要遍历，直至达到局部最优解，在样本量庞大时就显得收敛速度比较慢了，计算量非常庞大。 随机梯度下降仅以当前样本点进行最小值求解，通常无法达到真正局部最优解，但可以比较接近。属于大样本兼顾计算成本的折中方案。 最后&amp;#8195&amp;#8195当目标函数是凸函数时，梯度下降法的解是全局最优解。一般情况下，其解不保证是全局最优解。梯度下降法的收敛速度也未必是很快的。 参考资料 《统计学习方法》李航 著 清华大学出版社《运筹学》第四版 清华大学出版社]]></content>
      <categories>
        <category>math</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>math</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[my decision tree id3]]></title>
    <url>%2F2018%2F03%2F27%2Fmy-decision-tree-id3%2F</url>
    <content type="text"><![CDATA[前言 本文主要讲述一下决策树的基本算法–ID3生成决策树算法。一开始看例子的时候，我觉得决策树好简单呀，应该实现起来用pandas也能像实现朴素贝叶斯一样容易实现，可是到实践的时候才发现，这个实现起来也好难啊orz。刚开始尝试直接通过算gini指数用CART算法生成树，但发现当两个的gini指数相同时我的程序就没法择优选择了。。。这个还有待改进。。最后参考了一下机器学习实战这本书把id3生成和可视化决策树实现了（不得不说这本书可视化部分写得我都看不懂了。。。）。 正文定义分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点和有向边组成。结点有两种类型：内部节点和叶节点，内部节点表示一个特征或属性，叶节点表示一个类。 核心思想分类决策树的核心思想就是在一个数据集中找到一个最优特征，然后从这个特征的选值中找一个最优候选值(这段话稍后解释)，根据这个最优候选值将数据集分为两个子数据集，然后递归上述操作，直到满足指定条件为止。 优缺点优点 1：理解和解释起来简单，且决策树模型可以想象2：需要准备的数据量不大，而其他的技术往往需要很大的数据集，需要创建虚拟变量，去除不完整的数据，但是该算法对于丢失的数据不能进行准确的预测3：决策树算法的时间复杂度(即预测数据)是用于训练决策树的数据点的对数4：能够处理数字和数据的类别（需要做相应的转变），而其他算法分析的数据集往往是只有一种类型的变量5：能够处理多输出的问题6：使用白盒模型，如果给定的情况是在一个模型中观察到的，该条件的解释很容易解释的布尔逻辑，相比之下，在一个黑盒子模型（例如人工神经网络），结果可能更难以解释7：可能使用统计检验来验证模型，这是为了验证模型的可靠性8：从数据结果来看，它执行的效果很好，虽然它的假设有点违反真实模型 缺点 1：决策树算法学习者可以创建复杂的树，但是没有推广依据，这就是所谓的过拟合，为了避免这种问题，出现了剪枝的概念，即设置一个叶子结点所需要的最小数目或者设置树的最大深度2：决策树的结果可能是不稳定的，因为在数据中一个很小的变化可能导致生成一个完全不同的树，这个问题可以通过使用集成决策树来解决3：众所周知，学习一恶搞最优决策树的问题是NP——得到几方面完全的优越性，甚至是一些简单的概念。因此，实际决策树学习算法是基于启发式算法，如贪婪算法，寻求在每个节点上的局部最优决策。这样的算法不能保证返回全局最优决策树。这可以减轻训练多棵树的合奏学习者，在那里的功能和样本随机抽样更换。4：这里有一些概念是很难的理解的，因为决策树本身并不难很轻易的表达它们，比如说异或校验或复用的问题。5：决策树学习者很可能在某些类占主导地位时创建有有偏异的树，因此建议用平衡的数据训练决策树–当然最重要的还是容易过拟合！，所以迫切需要剪纸或者集成学习。 举个栗子各位立志于脱单的单身男女在找对象的时候就已经完完全全使用了决策树的思想。假设一位母亲在给女儿介绍对象时，有这么一段对话： 母亲：给你介绍个对象。女儿：年纪多大了？母亲：26。女儿：长的帅不帅？母亲：挺帅的。女儿：收入高不？母亲：不算很高，中等情况。女儿：是公务员不？母亲：是，在税务局上班呢。女儿：那好，我去见见。 这个女生的决策过程就是典型的分类决策树。相当于对年龄、外貌、收入和是否公务员等特征将男人分为两个类别：见或者不见。假设这个女生的决策逻辑如下：上图完整表达了这个女孩决定是否见一个约会对象的策略，其中绿色结点（内部结点）表示判断条件，橙色结点（叶结点）表示决策结果，箭头表示在一个判断条件在不同情况下的决策路径，图中红色箭头表示了上面例子中女孩的决策过程。 这幅图基本可以算是一棵决策树，说它“基本可以算”是因为图中的判定条件没有量化，如收入高中低等等，还不能算是严格意义上的决策树，如果将所有条件量化，则就变成真正的决策树了。（以上的决策树模型纯属瞎编乱造，旨在直观理解决策树，不代表任何女生的择偶观，各位女同志无须在此挑刺。。。） 决策树的学习决策树学习算法包含特征选择、决策树的生成与剪枝过程。决策树的学习算法通常是递归地选择最优特征，并用最优特征对数据集进行分割。开始时，构建根结点，选择最优特征，该特征有几种值就分割为几个子集，每个子集分别递归调用此方法，返回结点，返回的结点就是上一层的子结点。直到所有特征都已经用完，或者数据集只有一维特征为止。（这里就不介绍关于决策树的剪枝过程，日后再介绍） 特征选择特征选择问题希望选取对训练数据具有良好分类能力的特征，这样可以提高决策树学习的效率。如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有分类能力的（对象是否喜欢打游戏应该不会成为关键特征吧，也许也会……）。为了解决特征选择问题，找出最优特征，先要介绍一些信息论里面的概念。 熵（entropy）熵是表示随机变量不确定性的度量。设$X$是一个取有限个值的离散随机变量，其概率分布为$$P(X=x_i)=p_i, i=1,2,…,n$$则随机变量的熵定义为$$entropy(X) = -\sum_{i=1}^n P_ilog_2 P_i$$另外，$0log0=0$，当对数的底为2时，熵的单位为bit；为e时，单位为nat。熵越大，随机变量的不确定性就越大。从定义可验证$0&lt;=H(p)&lt;=logn$.python实现计算如下： 12calc_entropy = lambda P_: sum(map(lambda p: -p * np.log2(p), P_))# 其中P_为X的概率分布，p为X取某个随机变量的概率 条件熵（conditional entropy）设有随机变量$(X,Y)$，其联合概率分布为$$P(X=x_i,Y=y_i)=p_{ij}, i=1,2,…,n;j=1,2,…,m$$条件熵$H(Y|X)$表示在已知随机变量X的条件下随机变量Y的不确定性。随机变量X给定的条件下随机变量Y的条件熵$H(Y|X)$，定义为X给定条件下Y的条件概率分布的熵对X的数学期望$$entropy(Y|X) = \sum_{i=1}^k p_i H(Y|X=x_i)$$这里$p_i=P(X=x_i), i=1,2,…,n$。用python实现求条件熵时，只需要把P_更换为feat_value_cate_P再调用calc_entropy，然后把所有分组的概率与对应的熵相乘再相加： 12345# group为Y对于这个特征X取不同的值的分组for feat_value, group in groups: feat_value_P = len(group) / len(df) # 特征X取某值的概率 feat_value_cate_P = group[cate].value_counts() / group[cate].count() # 特征X取某值对应不同的类别的概率 feat_value_entropy += feat_value_P * calc_entropy(feat_value_cate_P) 信息增益（information gain）信息增益表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。特征A对训练数据集D的信息增益$g(D,A)$，定义为集合D的经验熵H(D)与特征A给定条件下D的经验条件熵H(D|A)之差，即$$g(D,A)=H(D)−H(D|A)$$这个差又称为互信息，表示由于特征A而使得对数据集D的分类不确定性减少的程度。信息增益大的特征具有更强的分类能力。设训练数据为$D$，$|D|$表示其样本容量，即样本个数。设$D$有$K$个类$C_k$，$k=1,2,…,K$，$|C_k|$为属于类$C_k$的样本个数，$\sum_{k=1}^K |C_k|=|D|$. 设特征A有n个不同的取值${a_1,a_2,…a_n}$, 根据特征A 的取值将D划分为n个子集$D_1,D_2,…,D_n$, $|D_i|$为的样本$D_i$个数，$\sum_{i=1}^n |D_i|=|D|$。记子集$D_i$中属于类$C_k$的样本的集合为$D_{ik}$，即$D_{ik}=D_i\bigcap C_k$，$|D_{ik}|$为$D_{ik}$的样本个数。 计算信息增益的算法如下： 输入：训练数据集$D$和特征$A$； 输出：特征A对训练数据集$D$的信息增益$g(D,A)$. 计算数据集D的经验熵H(D)$$H(D)=-\sum_{i=1}^k \frac{|C_k|}{|D|} log_2 \frac {|C_k|}{|D|}$$ 计算特征A对数据集D的经验条件熵$H(D|A)$$$H(D|A)=\sum_{i=1}^n \frac{|D_i|}{|D|}H(D_i)=\sum_{i=1}^n \frac{|D_i|}{|D|} \sum_{i=1}^K \frac{|D_{ik}|}{|D|} log_2 \frac{|D_{ik}|}{|D|}$$ 计算信息增益$$g(D,A)=H(D)−H(D|A)$$ 决策树的生成本次我们只介绍ID3算法，ID3算法由Ross Quinlan发明，建立在“奥卡姆剃刀”的基础上：越是小型的决策树越优于大的决策树（be simple简单理论）。ID3算法中根据信息增益评估和选择特征，每次选择信息增益最大的特征作为判断模块建立子结点。ID3算法可用于划分标称型数据集，没有剪枝的过程，为了去除过度数据匹配的问题，可通过裁剪合并相邻的无法产生大量信息增益的叶子节点（例如设置信息增益阀值）。使用信息增益的话其实是有一个缺点，那就是它偏向于具有大量值的属性。就是说在训练集中，某个属性所取的不同值的个数越多，那么越有可能拿它来作为分裂属性，而这样做有时候是没有意义的，另外ID3不能处理连续分布的数据特征，于是就有了C4.5算法。CART算法也支持连续分布的数据特征。123456789101112131415161718192021222324252627282930def select(df, features, cate , H_D): gain_dict = &#123;&#125; for feat in features: groups = df.groupby(feat) feat_value_entropy = 0 for feat_value, group in groups: feat_value_P = len(group) / len(df) # 特征取某值的概率 feat_value_cate_P = group[cate].value_counts() / group[cate].count() # 特征取某值对应不同的类别的概率 feat_value_entropy += feat_value_P * calc_entropy(feat_value_cate_P) imfor_gain = H_D - feat_value_entropy gain_dict[feat] = imfor_gain return max(gain_dict, key=lambda x:gain_dict[x])def create_tree(df, cate, H_D ): feat = df.columns[:-1].tolist() cate_values = df[cate].unique() if len(cate_values)==1: return cate_values[0] if len(feat) == 0: # 用完所有特征后 temp = df[cate].value_counts().to_dict() return max(temp, key=lambda x:temp[x]) # 取最多的类别作为返回值 best_feat = select(df, feat, cate, H_D) my_tree = &#123; best_feat:&#123;&#125; &#125; unique_feat_values = df[best_feat].unique() for feat_value in unique_feat_values: df_ = df[df[best_feat] == feat_value].copy() df_ = df_.drop(best_feat, axis=1) # 这里一定不能是df，必须是一个新的df_，才能使递归*中的feat*越来越小 my_tree[best_feat][feat_value] = create_tree(df_, cate, H_D ) return my_tree 我们这里用Python语言的字典套字典类型存储树的信息，简单方便。当然也可以定义一个新的数据结构存储树。来生成一个树：1234567df = pd.read_excel("TreeData.xlsx", index_col="id")cate = df.columns[-1]P_cate = df[cate].value_counts() / df[cate].count()H_D = calc_entropy(P_cate)tree = create_tree(df,cate, H_D)print(tree)# &#123;'有自己的房子': &#123;'否': &#123;'有工作': &#123;'否': '否', '是': '是'&#125;&#125;, '是': '是'&#125;&#125; 决策树的可视化我们主要用python的matplotlib来处理图像，它的annotate很方便用于注释。（以下代码来源：机器学习实战，我对其简单的更改了一下）先获得叶子节点个数和树的深度：1234567891011121314151617181920212223def get_leafs_num(tree_): num_leafs = 0 first_key = list(tree_.keys())[0] second_dict = tree_[first_key] for key in second_dict.keys(): if type(second_dict[key]).__name__ == "dict": num_leafs += get_leafs_num(second_dict[key]) else: num_leafs += 1 return num_leafsdef get_tree_depth(tree_): max_depth = 0 first_key = list(tree_.keys())[0] second_dict = tree_[first_key] for key in second_dict.keys(): if type(second_dict[key]).__name__ == "dict": # 如果还是字典，继续深入 this_depth = 1 + get_tree_depth(second_dict[key]) else: this_depth = 1 if this_depth &gt; max_depth: max_depth = this_depth return max_depth 然后再画图：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import matplotlib.pyplot as pltplt.rcParams['font.sans-serif']=['SimHei'] plt.rcParams['axes.unicode_minus']=False decision_node=&#123;"boxstyle": "sawtooth", "fc": "0.8", &#125;leaf_node=&#123;"boxstyle": "round4", "fc": "0.8"&#125;arrow_args=&#123;"arrowstyle": "&lt;-"&#125;def plot_node(node_txt, centerPt, parentPt, node_type): global ax1 ax1.annotate(node_txt, xy=parentPt, xycoords='axes fraction',xytext=centerPt, textcoords='axes fraction',va="center", ha="center", bbox=node_type, arrowprops=arrow_args)def plot_mid_text(cntrPt, parentPt, txt_string): # 在两个节点之间的线上写上字 global ax1 xMid = (parentPt[0] - cntrPt[0]) / 2.0 + cntrPt[0] yMid = (parentPt[1] - cntrPt[1]) / 2.0 + cntrPt[1] ax1.text(xMid, yMid, txt_string) # text() 的使用def plot_tree( tree_, parent_point, node_txt): global ax1,xOff,yOff,totalD,totalW num_leafs = get_leafs_num(tree_) depth = get_tree_depth(tree_) first_key = list(tree_.keys())[0] center_point = (xOff + (1.0 + float(num_leafs)) / 2.0 / totalW, yOff) plot_mid_text( center_point, parent_point, node_txt) # 在父子节点间填充文本信息 plot_node(first_key, center_point, parent_point, decision_node) # 绘制带箭头的注解 second_dict = tree_[first_key] yOff = yOff - 1.0 / totalD for key in second_dict.keys(): if type(second_dict[key]).__name__ == 'dict': # 判断是不是字典， plot_tree(second_dict[key], center_point, str(key)) # 递归绘制树形图 else: # 如果是叶节点 xOff = xOff + 1.0 / totalW plot_node(second_dict[key], (xOff, yOff), center_point, leaf_node) plot_mid_text((xOff, yOff), center_point, str(key)) yOff = yOff + 1.0 / totalDdef show_tree(tree_): global ax1,xOff,yOff,totalD,totalW fig = plt.figure(1, facecolor='white') fig.clf() # 清空绘图区 axprops = dict(xticks=[], yticks=[]) ax1 = plt.subplot(111, frameon=False, **axprops) totalW = float(get_leafs_num(tree_)) totalD = float(get_tree_depth(tree_)) xOff = -0.5 / totalW # 追踪已经绘制的节点位置 初始值为 将总宽度平分 在取第一个的一半 yOff = 1.0 plot_tree(tree_, (0.5, 1.0), '') # 调用函数，并指出根节点源坐标 plt.show() 下面用一个实例来可视化一下：1234tree = &#123;'有自己的房子': &#123;'否': &#123;'有工作': &#123;'否': '否', '是': '是'&#125;&#125;, '是': '是'&#125;&#125;print(tree)show_tree(tree) 可视化结果如下： 由于篇幅过长，完整代码（结构化封装）就不在这里给出，详情参见我的GitHub。 测试这里我们采用uci的lense隐形眼镜测试集,总样本为24个，四个特征，三个类别。我们通过网络爬虫，直接从该网址抓取数据，并转换为dataframe类型。 – 3 Classes: 1 : the patient should be fitted with hard contact lenses, 2 : the patient should be fitted with soft contact lenses, 3 : the patient should not be fitted with contact lenses. – 4 Features: 1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic 2. spectacle prescription: (1) myope, (2) hypermetrope 3. astigmatic: (1) no, (2) yes 4. tear production rate: (1) reduced, (2) normal 下面我们给出代码：1234567891011121314151617181920212223242526from ID3 import ID3_treeimport requestsimport pandas as pddef get_data(): url = "http://archive.ics.uci.edu/ml/machine-learning-databases/lenses/lenses.data" data = requests.get(url).text verctors = data.split('\n') verctors = [ver.split() for ver in verctors] features = ["id","age","prescript","astigmatic","tearRate","category"] df = pd.DataFrame(verctors,columns=features, dtype=int) df = df.set_index("id").dropna() key_list = [&#123;"1":"young", "2":"pre-presbyopic", "3":"presbyopic"&#125;, &#123;"1": "myope", "2": "hypermetrope"&#125; , &#123;"1": "no", "2": "yes"&#125;, &#123;"1": "reduced", "2":"normal"&#125;,&#123;"1":"hard","2":"soft","3":"no lenses"&#125;] for i in range(5): df.iloc[:,i] = df.iloc[:,i].apply(lambda x:key_list[i][x]) return dfif __name__ == "__main__": df = get_data() # print(df) id3_tree = ID3_tree(df) id3_tree = id3_tree.train(df) my_tree = id3_tree.my_tree print(my_tree) id3_tree.show_tree(my_tree) 得出的决策树如下： 后续由于本文只给出了ID3算法生成决策树和决策树的可视化，日后我将继续给出C4.5的生成决策树算法、决策树的减枝问题与及CART分类和回归树的构造。然后我们还可以把它拓宽，引入集成学习的随机森林。 作者时间精力有限，我就先写到这里啦。如有疑问，记得联系我哦。 参考文献 《统计学习方法》李航 著 清华大学出版社《机器学习实战》Peter Harrington 著 人民邮电出版社]]></content>
      <categories>
        <category>machine_leanring</category>
        <category>code</category>
      </categories>
      <tags>
        <tag>machine_leanring</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Radial basis function kernel]]></title>
    <url>%2F2018%2F03%2F18%2FRadial-basis-function-kernel%2F</url>
    <content type="text"><![CDATA[高斯径向基函数简介：在机器学习中，（高斯）径向基函数核（英语：Radial basis function kernel），或称为RBF核，是一种常用的核函数。它是支持向量机分类中最为常用的核函数。—— 维基百科 高斯径向基函数高斯径向基函数公式如下：$$K(x_1,x_2)=\exp{(-\frac{\parallel x_1-x_2 \parallel^2 }{2\sigma^2})}, \sigma&gt;0$$ 那么它有什么几何意义呢?先看看x经过映射以后，在高维空间里这个点到原点的距离公式： $$ \parallel x_i-0\parallel^2 = \parallel x_i \parallel^2=\left \langle \Phi (x_i), \Phi (x_i)\right \rangle=K(x_i,x_i)=1$$这表明样本x映射到高维空间后，在高维空间中的点$\Phi (x_i)$到高维空间中原点的距离为1，也即$\Phi (x_i)$存在于一个超球面上。 为什么核函数能映射到高维空间呢？先考虑普通的多项式核函数：$K(x,y)=(x^T\cdot y+m)^p$,其中$x,y\in \mathbb{R}^n$，多项式参数$p,m\in \mathbb{R}$考虑$x=(x_1,x_2),y=(y_1,y_2),m=0,p=2$，即$K(x,y)=(x^T\cdot y)^2=x_1^2y_1^2+2x_1x_2y_1y_2+x_2^2y_2^2$现在回到之前的映射$k(x,y)=\left \langle \Phi(x),\Phi(y)\right \rangle$，并取$\Phi(x)=(x_1^2,\sqrt{2}x_1x_2,x_2^2)$则有$k(x,y)=\left \langle \Phi(x),\Phi(y)\right \rangle=x_1^2y_1^2+2x_1x_2y_1y_2+x_2^2y_2^2=(x^T\cdot y)^2=K(x,y)$这就是前面的$K(x,y)$，因此，该核函数就将2维映射到了3维空间。 径向基核又为什么能够映射到无限维空间呢？看完了普通多项式核函数由2维向3维的映射，再来看看高斯径向基函数会把2维平面上一点映射到多少维。$$\begin{eqnarray}K(x,y) &amp; = &amp; \exp(| x_1-x_2 |^2 ) \&amp; = &amp; \exp(-(x_1-y_1)^2-(x_2-y_2)^2) \&amp; = &amp; \exp(-x_1^2+2x_1y_1-y_1^2-x_2^2+2x_2y_2-y_2^2) \&amp; = &amp; \exp(-|x|^2)\exp(-|y|^2)\exp(2x^Ty)\\end{eqnarray}$$将最后一项泰勒展开你就会恍然大悟：$$K(x,y)=\exp(-|x|^2)\exp(-|y|^2)\sum_{n=0}^{\infty}\frac{(2x^Ty)^n}{n!}$$ 再具体一点：高斯核是这样定义的：$K(x_1,x_2)=\exp{(-\frac{\parallel x_1-x_2 \parallel^2 }{2\sigma^2})}, \sigma&gt;0$尽管我不会解释它（但相信我）高斯核可以简单修正为这个样子：$K(x_1,x_2)=\exp(-\frac{x_1\cdot x_2}{\sigma^2}),\sigma&gt;0$，这里$x_1\cdot x_2$可解释为内积。再用泰勒展开就会得到$K(x_1,x_2)=\sum_{n=0}^{\infty}\frac{(x_1\cdot x_2)^n}{\sigma^nn!}$求和号里面的元素是不是看起来很熟悉呢？没错，这就是一个n次多项式核。因为每一个多项式核都将一个向量投影到更高维的空间中，因此高斯核是那些$degree\geq0$的多项式核的组合，所以我们说高斯核是投影到无穷维空间中。 参考Quora上的问题：https://www.quora.com/Machine-Learning/Why-does-the-RBF-radial-basis-function-kernel-map-into-infinite-dimensional-space-mentioned-many-times-in-machine-learning-lectures 最后初学者使用markdown与LaTeX的语法真不适应啊，就写到这里吧，写篇博客太累了orz饭都没吃，关于RBF神经网络的话，以后用到再来讲吧，累死我惹。如有疑问，欢迎咨询，联系方式见“关于”页面。]]></content>
      <categories>
        <category>math</category>
        <category>theory</category>
      </categories>
      <tags>
        <tag>machine_leanring</tag>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 的闭包、装饰器]]></title>
    <url>%2F2018%2F03%2F17%2Fpython-%E7%9A%84%E9%97%AD%E5%8C%85%E3%80%81%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[一、闭包（Closure）什么是闭包？ 在计算机科学中，闭包（英语：Closure），又称词法闭包（Lexical Closure）或函数闭包（function closures），是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。—— 维基百科) 这里我给个简单的解释：一个闭包就是你调用了一个函数A，这个函数A返回了一个函数B给你。这个返回的函数B就叫做闭包。你在调用函数A的时候传递的参数就是自由变量。 举个例子：1234567def func(name): def inner_func(age): print 'name:', name, 'age:', age return inner_funcbb = func('matrix')bb(26) # &gt;&gt;&gt; name: matrix age: 26 这里面调用func的时候就产生了一个闭包– inner_func,并且该闭包持有自由变量– name，因此这也意味着，当函数func的生命周期结束之后，name这个变量依然存在，因为它被闭包引用了，所以不会被回收。 也有人说这种内部函数inner_func可以使用外部函数的变量name的行为就叫闭包。 二、装饰器（Decorator）什么是装饰器？ “装饰器的功能是将被装饰的函数当作参数传递给与装饰器对应的函数（名称相同的函数），并返回包装后的被装饰的函数” 听起来有点绕，没关系，直接看示意图,其中a为 与装饰器@a对应的函数，b为装饰器修饰的函数，装饰器@a的作用是：简而言之：@a 就是将 b 传递给 a()，并返回新的 b = a(b) 举个例子 先导入包： 1234from functools import reduceimport mathimport logginglogging.basicConfig(level=logging.INFO) 定义一个检查参数的装饰器： 123456789def checkParams(fn): def wrapper(*numbers): temp = map(lambda x:isinstance(x,(int,)),numbers) # 检查参数是否都为整型 if reduce(lambda x,y: x and y, temp): # 若都为整型 return fn(*numbers) # 则调用fn(*numbers)返回计算结果 #否则通过logging记录错误信息，并友好退出 logging.warning("variable numbers cannot be added") return return wrapper #fn引用gcd，被封存在闭包的执行环境中返回 然后定义求最大公约数的函数（能求多个的最大公约数）： 123def gcd(*numbers): """return the greatest common divisor of the given integers.""" return reduce(math.gcd, numbers) 调用 123&gt;&gt;&gt;gcd = checkParams(gcd)&gt;&gt;&gt;gcd(3, 'hello')# 输出 WARNING:root: variable numbers cannot be added 注意checkParams函数： 首先看参数fn，当我们调用checkParams(gcd)的时候，它将成为函数对象gcd的一个本地(Local)引用； 在checkParams内部，我们定义了一个wrapper函数，添加了参数类型检查的功能，然后调用了fn(*numbers)，根据LEGB法则，解释器将搜索几个作用域，并最终在(Enclosing层) checkParams函数的本地作用域中找到fn； 注意最后的return wrapper，这将创建一个闭包，fn变量(gcd函数对象的一个引用)将会封存在闭包的执行环境中，不会随着checkParams的返回而被回收； 当调用gcd = checkParams(gcd)时，gcd指向了新的wrapper对象，它添加了参数检查和记录日志的功能，同时又能够通过封存的fn，继续调用原始的gcd进行最大公约数运算。 因此调用gcd(3, ‘hello’)将不会返回计算结果，而是打印出日志：root: variable numbers cannot be added。 有人觉得add = checkParams(add)这样的写法未免太过麻烦，于是python提供了一种更优雅的写法，被称为语法糖：12345@checkParamsdef lcm(*numbers): """return lowest common multiple.""" f = lambda a,b:int((a*b)/gcd(a,b)) return reduce(f, numbers) 其实这只是一种写法上的优化，解释器仍然会将它转化为gcd = checkParams(gcd)来执行。]]></content>
      <categories>
        <category>math</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>fun math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo常用命令笔记]]></title>
    <url>%2F2018%2F03%2F13%2Fhexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[hexo123npm install hexo -g #安装npm update hexo -g #升级hexo init #初始化 简写12345hexo n "我的博客" == hexo new "我的博客" #新建文章hexo p == hexo publishhexo g == hexo generate#生成hexo s == hexo server #启动服务预览hexo d == hexo deploy#部署 服务器1234hexo server #Hexo 会监视文件变动并自动更新，您无须重启服务器。hexo server -s #静态模式hexo server -p 5000 #更改端口hexo server -i 192.168.1.1 #自定义 IP 123hexo clean #清除缓存 网页正常情况下可以忽略此条命令hexo g #生成静态网页hexo d #开始部署 监视文件变动12hexo generate #使用 Hexo 生成静态文件快速而且简单hexo generate --watch #监视文件变动 完成后部署123# 以下两个命令的作用是相同的hexo generate --deployhexo deploy --generate 简写12hexo deploy -ghexo server -g 草稿1hexo publish [layout] &lt;title&gt; 模版12345hexo new &quot;postName&quot; #新建文章hexo new page &quot;pageName&quot; #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）hexo deploy #将.deploy目录部署到GitHub 如：123hexo new [layout] &lt;title&gt;hexo new photo &quot;My Gallery&quot;hexo new &quot;Hello World&quot; --lang tw 变量 描述 layout 布局 title 标题 date 文件建立日期 12345678title: 使用Hexo搭建个人博客layout: postdate: 2014-03-03 19:07:43comments: truecategories: Blogtags: [Hexo]keywords: Hexo, Blogdescription: 生命在于折腾，又把博客折腾到Hexo了。给Hexo点赞。]]></content>
      <categories>
        <category>hexo</category>
        <category>Instructions</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[my_knn]]></title>
    <url>%2F2018%2F03%2F13%2Fmy-knn%2F</url>
    <content type="text"><![CDATA[关于在一个月前，需要用1nn做二分类的测试的时候，开始因为用sklearn训练数据时用错了数据集，百思不得其解，于是自己写了个knn来训练，当时写好后，才真正把原理给弄懂了orz，原来是数据集训练时用错了。。。改正后对比了一下自己的knn和sklearn的knn的准确率都差不多（也就是说测试通过啦），就上传到了我的GitHub。 当时我虽然有个用腾讯云搭建的博客，但基本上都没在上面写过了orz，本博客当时还没有问世，正好基于GitHub的服务器最近搭了这个博客，空空的也不好，最近老师第一讲就讲knn，那就把之前的代码贴上吧。 原理对于一个输入的测试数据，计算该样本点到训练数据各样本点的距离，然后对所有距离由小到大排列，取前k个数据；统计该k个数据中对应的标签出现次数最多的标签，则该测试样本就被标记为该标签。 算法 输入: 训练数据集：$T={(X_1,y_1),(X_2,y_2),…,(X_N,y_N)}$, 其中$X_i={x_i^1,x_i^2,…,x_i^n}$,有n个特征，N个样本点; 输入：最近邻个数k，及要预测的样本点$X_0={x_0^1,,x_0^2,…,x_0^n}$; 计算：样本点X_0到训练数据集T中各样本点的距离（一般为欧氏距离）; 排序：将以上算出的距离由小到大排序，并选出前k个距离数据; 统计：统计前k个距离数据中各个标签对应的个数，选出个数最多的那个标签，即为该样本点预测的结果。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import numpy as npfrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitclass my_knn(object): """docstring for my_knn""" def __init__(self, k): super(my_knn, self).__init__() self.k = k def train(self, X_train, y_train): self.X_train, self.y_train = np.array(X_train), np.array(y_train) if len(self.X_train) != len(self.y_train): raise ValueError("X_test,y_test or y_train was not equail!" "The length of X_test,y_test is %s" "But the length of y_train is %s" % (len(self.X_train), len(self.y_train))) return self def predict_one(self, X): dist2xtrain = np.sum((X - self.X_train)**2, axis=1)**0.5 index = dist2xtrain.argsort() # 从小到大（近到远） label_count = &#123;&#125; for i in range(self.k): label = self.y_train[index[i]] label_count[label] = label_count.get(label, 0) + 1 # 将label_count的值从大到小排列label_count的键 y_predict = sorted(label_count, key=lambda x: label_count[x], reverse=True)[0] return y_predict def predict_all(self, X): return np.array(list(map(self.predict_one, X))) def calc_accuracy(self, X, y): predict = self.predict_all(X) total = X.shape[0] right = sum(predict == y) accuracy = right/total return accuracyif __name__ == "__main__": data_set = load_iris() datas = data_set["data"] labels = data_set['target'] X_train, X_test, y_train, y_test = train_test_split(datas, labels, test_size=0.4, random_state=0) knn = my_knn(1) knn = knn.train(X_train,y_train) accuracy = knn.calc_accuracy(X_test,y_test) print("%.3f%%" % (accuracy * 100)) from sklearn.neighbors import KNeighborsClassifier neigh = KNeighborsClassifier(n_neighbors=1) neigh.fit(X_train, y_train) print(neigh.score(X_train,y_train)) print(neigh.score(X_test, y_test)) 最后关于对knn的kd树加速这部分还需要日后的后续学习，这里就先不说啦（其实是我也不会23333）。由于我对markdown语法不太熟悉，写起文章来的有点别扭还望理解（逃。 写给自己 还是要多花点时间学习啊！一个多月没学习就忘得差不多了orz,还好看一下就能回想起来。多练习吧！]]></content>
      <categories>
        <category>machine_leanring</category>
        <category>code</category>
      </categories>
      <tags>
        <tag>machine_leanring</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[my_bayes]]></title>
    <url>%2F2018%2F03%2F13%2Fmy-bayes%2F</url>
    <content type="text"><![CDATA[前言本周一晚上老师讲到了naive bayes（朴素贝叶斯分类器），于是自己用python来实现了一下。现在这个脚本对于比较大的数据可能会计算的比较慢，还需要以后慢慢再研究一下里面的加速。 本程序主要利用了pandas里dataframe的groupby分组函数，大大的方便了对数据的统计。对于条件概率，有不同的标签，不同的特征和特征里的不同数据，我们采用了dict数据结构，第一层key为标签，value是一个新的dict；第二层（前面那个新的dict）的key为特征，value是一个Series或者字典；第三层的key/index为特征的取值，value为频数/概率。、、（虽然看起来比较拗口，但我感觉这样能够比较清晰的分清了各个条件概率了，如果你有更好的方法，欢迎留言给我，谢谢。） 算法 输入：训练数据集及其标签集，要预测的数据集 统计各标签出现的频数，并拉普拉斯平滑，计算先验概率 统计在各标签下各个特征的频数，并拉普拉斯平滑，计算条件概率 查找要预测数据集各特征在不同标签下的条件概率和先验概率相乘得到（半）后验概率 对半后验概率进行从大到小排序，选出最大值对应的标签，即为预测结果 实例化测试ps：这里半后验概率为我自己的定义：$P(Y_j) *\prod_{i=1}^N P(A_i|Y_j) ; i:1\to n_{feature}; j:1\to n_{label}$ 解释本程序主要分为一下部分： 定义一个bayes分类器（类） 计算先验概率 计算所有条件概率 进行调用训练 对测试数据进行预测 实例化测试 以上各对应之下的各个函数：（废话不多说，直接上代码） 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import numpy as npimport pandas as pdclass my_naive_bayes(object): def __init__(self, df): super(my_naive_bayes, self).__init__() self.df = df self.X_train = df.iloc[:,:-1] self.y_train = df.iloc[:,-1] self.label_set = set(self.y_train) self.features = df.columns[:-1] self.label_name = df.columns[-1] self.feature_dict = &#123;&#125; self.n_sample = len(df) def get_prior_p(self, g): n = len(g) prior_p = &#123;&#125; for label in self.label_set: prior_p[label] = g.size()[label] / self.n_sample return prior_p def get_cond_p(self, g): cond_p = &#123;&#125; for label, group in g: cond_p[label] = &#123;&#125; for feature in self.features: counts = group[feature].value_counts() cond_p[label][feature] = counts / sum(counts) return cond_p def train(self, ): for feature in self.features: self.feature_dict[feature] = set(self.df[feature]) g = self.df.groupby(self.label_name) self.prior_p = self.get_prior_p(g) self.cond_p = self.get_cond_p(g) return self def predict_one(self, test_X): semi_post_p = &#123;&#125; for label in self.label_set: temp = 1 for feature in self.features: temp = temp * self.cond_p[label][feature][test_X[feature]] semi_post_p[label] = self.prior_p[label] * temp return max(semi_post_p, key=semi_post_p.get)if __name__ == '__main__': df = pd.read_excel("bayes_data.xlsx",index_col="index") # n = len(df) # train_n = int(n*0.6) # train_df = df[:train_n] # test_df = df[train_n:] bayes = my_naive_bayes(df) bayes = bayes.train() test_x = df.loc[6] label = bayes.predict_one(test_x) print(label) 最后，好好学习，天天向上！]]></content>
      <categories>
        <category>machine_leanring</category>
        <category>code</category>
      </categories>
      <tags>
        <tag>machine_leanring</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18_03_07]]></title>
    <url>%2F2018%2F03%2F07%2F18-03-07%2F</url>
    <content type="text"><![CDATA[今天是开学第三天，各种事情莫名烦躁。]]></content>
      <categories>
        <category>diary</category>
      </categories>
      <tags>
        <tag>diary</tag>
        <tag>life-style</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SVM explained-well]]></title>
    <url>%2F2018%2F03%2F02%2FSVM-explained-well%2F</url>
    <content type="text"><![CDATA[Support vector machines (SVM) User copperking stepped up to the plate: “We have 2 colors of balls on the table that we want to separate. We get a stick and put it on the table, this works pretty well right? Some villain comes and places more balls on the table, it kind of works but one of the balls is on the wrong side and there is probably a better place to put the stick now. SVMs try to put the stick in the best possible place by having as big a gap on either side of the stick as possible. Now when the villain returns the stick is still in a pretty good spot. There is another trick in the SVM toolbox that is even more important. Say the villain has seen how good you are with a stick so he gives you a new challenge. svm7-300x167.png There’s no stick in the world that will let you split those balls well, so what do you do? You flip the table of course! Throwing the balls into the air. Then, with your pro ninja skills, you grab a sheet of paper and slip it between the balls. Now, looking at the balls from where the villain is standing, they balls will look split by some curvy line. Boring adults the call balls data, the stick a classifier, the biggest gap trick optimization, call flipping the table kernelling and the piece of paper a hyperplane.” I think the last step is the most beautiful no mater in mathematic or machine learning! Hope it will help you. source: http://bytesizebio.net/2014/02/05/support-vector-machines-explained-well/]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>machine_leanring</tag>
        <tag>fun math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[new-post]]></title>
    <url>%2F2018%2F02%2F27%2Fnew-post%2F</url>
    <content type="text"><![CDATA[this is a test blog.welcome to treamy’s world. Create a new post1$ hexo new "My New Post" add some code1&gt;&gt;&gt; print("My New Post") 标签页面1&gt;运行以下命令1$ hexo new page "tags" 同时，在/source目录下会生成一个tags文件夹，里面包含一个index.md文件 推送到服务器上1$ hexo g -d 先generate一下生成静态页面，再deploy部署到服务器。好像hexo d -g也可以。。一次记错了写成这个也行。。我也不知道为啥在一个网页上看到说他们左右是相同的，还是用前面那个较好解读的吧。]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F02%2F27%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
